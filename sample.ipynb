{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a77807f92f26ee",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "id": "fbc121e30a2defb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T12:35:07.664861Z",
     "start_time": "2025-03-13T12:35:07.651973Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import warnings\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For NLP chatbot\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import random\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\farou\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\farou\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\farou\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 111
  },
  {
   "cell_type": "markdown",
   "id": "6e16c82b9c82a08f",
   "metadata": {},
   "source": [
    "# Data Loading and Exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "c3c4253ba58939f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T12:35:07.814302Z",
     "start_time": "2025-03-13T12:35:07.790385Z"
    }
   },
   "source": [
    "df = pd.read_csv('data/edited_skill_exchange_dataset.csv')"
   ],
   "outputs": [],
   "execution_count": 112
  },
  {
   "cell_type": "markdown",
   "id": "d4d3c9e161375343",
   "metadata": {},
   "source": [
    "\n",
    "# Display basic information about the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "eb947f599c010912",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T12:35:07.835325Z",
     "start_time": "2025-03-13T12:35:07.827491Z"
    }
   },
   "source": [
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nData Types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nSample Data:\")\n",
    "print(df.head())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (10000, 6)\n",
      "\n",
      "Data Types:\n",
      "user_id            int64\n",
      "joinedDate        object\n",
      "joinedCourses     object\n",
      "skills            object\n",
      "desired_skills    object\n",
      "isVerified          bool\n",
      "dtype: object\n",
      "\n",
      "Sample Data:\n",
      "   user_id  joinedDate                            joinedCourses  \\\n",
      "0        1  2022-08-28  Machine Learning, CSS, Excel, SQL, HTML   \n",
      "1        2  2023-12-04  Data Science, Excel, Python, JavaScript   \n",
      "2        3  2023-04-10          JavaScript, Python, Excel, Java   \n",
      "3        4  2022-01-30              AI, Machine Learning, Excel   \n",
      "4        5  2022-09-07                                   Python   \n",
      "\n",
      "                               skills  \\\n",
      "0                           HTML, SQL   \n",
      "1   HTML, CSS, JavaScript, Excel, SQL   \n",
      "2                     HTML, CSS, Java   \n",
      "3  HTML, Excel, SQL, Java, Blockchain   \n",
      "4                 CSS, JavaScript, AI   \n",
      "\n",
      "                                      desired_skills  isVerified  \n",
      "0  CSS, Java, Machine Learning, Blockchain, Data ...       False  \n",
      "1              JavaScript, Python, Java, Node.js, AI        True  \n",
      "2                                  CSS, SQL, Node.js        True  \n",
      "3  SQL, Node.js, Machine Learning, Blockchain, Da...        True  \n",
      "4                    HTML, CSS, Java, AI, Blockchain       False  \n"
     ]
    }
   ],
   "execution_count": 113
  },
  {
   "cell_type": "markdown",
   "id": "e82f1d3247de28ea",
   "metadata": {},
   "source": [
    "## 2. Data Preparation and Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "577b2c28632f85ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T12:35:08.312587Z",
     "start_time": "2025-03-13T12:35:07.910024Z"
    }
   },
   "source": [
    "# Comprehensive Data Cleaning Pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "from dateutil.parser import parse\n",
    "import re\n",
    "\n",
    "def clean_dataset(df):\n",
    "    print(\"Starting comprehensive data cleaning process...\")\n",
    "    print(f\"Initial shape: {df.shape}\")\n",
    "\n",
    "    # 1. Make a copy to avoid modifying the original dataframe\n",
    "    df_clean = df.copy()\n",
    "\n",
    "    # 2. Fix data types\n",
    "    # Convert joinedDate to datetime with error handling\n",
    "    df_clean['joinedDate'] = pd.to_datetime(df_clean['joinedDate'], errors='coerce')\n",
    "\n",
    "    # Calculate membership duration (in days) from a fixed reference point\n",
    "    reference_date = pd.Timestamp('2025-03-12')\n",
    "    df_clean['membershipDuration'] = (reference_date - df_clean['joinedDate']).dt.days\n",
    "\n",
    "    # 3. Standardize text columns and handle special characters\n",
    "    def deep_clean_text(text):\n",
    "        if not isinstance(text, str):\n",
    "            return \"\"\n",
    "        # Remove special characters except commas\n",
    "        text = re.sub(r'[^\\w\\s,]', '', text)\n",
    "        # Normalize whitespace around commas\n",
    "        text = re.sub(r'\\s*,\\s*', ', ', text)\n",
    "        # Split by comma, strip whitespace, remove empty items, and rejoin\n",
    "        items = [item.strip() for item in text.split(',') if item.strip()]\n",
    "        # Remove duplicates while preserving order\n",
    "        seen = set()\n",
    "        unique_items = [x for x in items if not (x in seen or seen.add(x))]\n",
    "        return ', '.join(unique_items) if unique_items else \"\"\n",
    "\n",
    "    # Apply advanced text cleaning to specified columns\n",
    "    text_columns = ['joinedCourses', 'skills', 'desired_skills']\n",
    "    for col in text_columns:\n",
    "        df_clean[col] = df_clean[col].apply(deep_clean_text)\n",
    "\n",
    "    # 4. Handle missing values\n",
    "    # Count missing values before imputation\n",
    "    missing_before = df_clean.isnull().sum()\n",
    "    print(\"\\nMissing values before imputation:\")\n",
    "    print(missing_before[missing_before > 0])\n",
    "\n",
    "    # Fill missing text fields with empty strings\n",
    "    for col in text_columns:\n",
    "        df_clean[col] = df_clean[col].fillna(\"\")\n",
    "\n",
    "    # 5. Create derived features\n",
    "    # Count features with consistent handling of empty strings\n",
    "    df_clean['course_count'] = df_clean['joinedCourses'].apply(lambda x: len(x.split(',')) if x else 0)\n",
    "    df_clean['skills_count'] = df_clean['skills'].apply(lambda x: len(x.split(',')) if x else 0)\n",
    "    df_clean['desired_skills_count'] = df_clean['desired_skills'].apply(lambda x: len(x.split(',')) if x else 0)\n",
    "\n",
    "    # Calculate skill overlap (common skills between a user's skills and desired skills)\n",
    "    def calculate_overlap(row):\n",
    "        if not isinstance(row['skills'], str) or not isinstance(row['desired_skills'], str):\n",
    "            return 0\n",
    "        skills_set = set([s.strip() for s in row['skills'].split(',') if s.strip()])\n",
    "        desired_set = set([s.strip() for s in row['desired_skills'].split(',') if s.strip()])\n",
    "        return len(skills_set.intersection(desired_set))\n",
    "\n",
    "    df_clean['skill_overlap'] = df_clean.apply(calculate_overlap, axis=1)\n",
    "\n",
    "    # 6. Handle boolean values consistently\n",
    "    df_clean['isVerified'] = df_clean['isVerified'].astype(int)\n",
    "\n",
    "    # 7. Handle numerical outliers using IQR method\n",
    "    numerical_cols = ['membershipDuration', 'course_count', 'skills_count', 'desired_skills_count']\n",
    "\n",
    "    for col in numerical_cols:\n",
    "        Q1 = df_clean[col].quantile(0.25)\n",
    "        Q3 = df_clean[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        # Count outliers\n",
    "        outliers = ((df_clean[col] < lower_bound) | (df_clean[col] > upper_bound)).sum()\n",
    "        if outliers > 0:\n",
    "            print(f\"Found {outliers} outliers in {col}\")\n",
    "\n",
    "        # Cap outliers instead of removing them\n",
    "        df_clean[col] = df_clean[col].clip(lower_bound, upper_bound)\n",
    "\n",
    "    # 8. Add user activity score (weighted combination of features)\n",
    "    df_clean['user_activity_score'] = (\n",
    "        0.3 * df_clean['course_count'] / df_clean['course_count'].max() +\n",
    "        0.3 * df_clean['skills_count'] / df_clean['skills_count'].max() +\n",
    "        0.2 * df_clean['membershipDuration'] / df_clean['membershipDuration'].max() +\n",
    "        0.2 * df_clean['isVerified']\n",
    "    ).round(3)\n",
    "\n",
    "    # 9. Consistency check - ensure user_id is unique\n",
    "    if df_clean['user_id'].duplicated().any():\n",
    "        print(f\"Warning: Found {df_clean['user_id'].duplicated().sum()} duplicate user IDs\")\n",
    "        # Keep first occurrence of duplicated user_ids\n",
    "        df_clean = df_clean.drop_duplicates(subset=['user_id'], keep='first')\n",
    "\n",
    "    # 10. Final validation checks\n",
    "    # Check for any remaining nulls\n",
    "    remaining_nulls = df_clean.isnull().sum().sum()\n",
    "    if remaining_nulls > 0:\n",
    "        print(f\"Warning: Still have {remaining_nulls} null values in the dataset\")\n",
    "\n",
    "    print(f\"\\nFinal shape after cleaning: {df_clean.shape}\")\n",
    "    print(\"Data cleaning completed successfully\")\n",
    "\n",
    "    return df_clean\n",
    "\n",
    "# Apply the comprehensive cleaning function\n",
    "df_cleaned = clean_dataset(df)\n",
    "\n",
    "# Show a sample of the cleaned data\n",
    "print(\"\\nSample of cleaned data:\")\n",
    "print(df_cleaned.head())\n",
    "df = df_cleaned\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"\\nSummary statistics:\")\n",
    "print(df_cleaned.describe())\n",
    "\n",
    "# Print column information\n",
    "print(\"\\nColumn information after cleaning:\")\n",
    "for col in df_cleaned.columns:\n",
    "    col_type = df_cleaned[col].dtype\n",
    "    if col_type == 'object':\n",
    "        n_unique = df_cleaned[col].nunique()\n",
    "        print(f\"{col}: {col_type} with {n_unique} unique values\")\n",
    "    else:\n",
    "        print(f\"{col}: {col_type}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting comprehensive data cleaning process...\n",
      "Initial shape: (10000, 6)\n",
      "\n",
      "Missing values before imputation:\n",
      "Series([], dtype: int64)\n",
      "Found 26 outliers in skills_count\n",
      "Found 35 outliers in desired_skills_count\n",
      "\n",
      "Final shape after cleaning: (10000, 12)\n",
      "Data cleaning completed successfully\n",
      "\n",
      "Sample of cleaned data:\n",
      "   user_id joinedDate                            joinedCourses  \\\n",
      "0        1 2022-08-28  Machine Learning, CSS, Excel, SQL, HTML   \n",
      "1        2 2023-12-04  Data Science, Excel, Python, JavaScript   \n",
      "2        3 2023-04-10          JavaScript, Python, Excel, Java   \n",
      "3        4 2022-01-30              AI, Machine Learning, Excel   \n",
      "4        5 2022-09-07                                   Python   \n",
      "\n",
      "                               skills  \\\n",
      "0                           HTML, SQL   \n",
      "1   HTML, CSS, JavaScript, Excel, SQL   \n",
      "2                     HTML, CSS, Java   \n",
      "3  HTML, Excel, SQL, Java, Blockchain   \n",
      "4                 CSS, JavaScript, AI   \n",
      "\n",
      "                                      desired_skills  isVerified  \\\n",
      "0  CSS, Java, Machine Learning, Blockchain, Data ...           0   \n",
      "1               JavaScript, Python, Java, Nodejs, AI           1   \n",
      "2                                   CSS, SQL, Nodejs           1   \n",
      "3  SQL, Nodejs, Machine Learning, Blockchain, Dat...           1   \n",
      "4                    HTML, CSS, Java, AI, Blockchain           0   \n",
      "\n",
      "   membershipDuration  course_count  skills_count  desired_skills_count  \\\n",
      "0                 927             5             2                     5   \n",
      "1                 464             4             5                     5   \n",
      "2                 702             4             3                     3   \n",
      "3                1137             3             5                     5   \n",
      "4                 917             1             3                     5   \n",
      "\n",
      "   skill_overlap  user_activity_score  \n",
      "0              0                0.545  \n",
      "1              1                0.734  \n",
      "2              1                0.689  \n",
      "3              2                0.789  \n",
      "4              2                0.346  \n",
      "\n",
      "Summary statistics:\n",
      "           user_id                     joinedDate    isVerified  \\\n",
      "count  10000.00000                          10000  10000.000000   \n",
      "mean    5000.50000  2023-01-03 07:45:59.040000256      0.506000   \n",
      "min        1.00000            2022-01-01 00:00:00      0.000000   \n",
      "25%     2500.75000            2022-07-07 00:00:00      0.000000   \n",
      "50%     5000.50000            2023-01-04 00:00:00      1.000000   \n",
      "75%     7500.25000            2023-07-03 00:00:00      1.000000   \n",
      "max    10000.00000            2024-01-01 00:00:00      1.000000   \n",
      "std     2886.89568                            NaN      0.499989   \n",
      "\n",
      "       membershipDuration  course_count  skills_count  desired_skills_count  \\\n",
      "count        10000.000000  10000.000000  10000.000000           10000.00000   \n",
      "mean           798.676400      3.011200      3.412900               4.88140   \n",
      "min            436.000000      1.000000      1.000000               1.00000   \n",
      "25%            618.000000      2.000000      2.000000               4.00000   \n",
      "50%            798.000000      3.000000      3.000000               5.00000   \n",
      "75%            979.000000      4.000000      4.000000               6.00000   \n",
      "max           1166.000000      5.000000      7.000000               9.00000   \n",
      "std            209.582501      1.410629      1.405209               1.63756   \n",
      "\n",
      "       skill_overlap  user_activity_score  \n",
      "count   10000.000000         10000.000000  \n",
      "mean        1.187200             0.565130  \n",
      "min         0.000000             0.181000  \n",
      "25%         0.000000             0.457000  \n",
      "50%         1.000000             0.564000  \n",
      "75%         2.000000             0.674000  \n",
      "max         7.000000             0.999000  \n",
      "std         1.012847             0.148752  \n",
      "\n",
      "Column information after cleaning:\n",
      "user_id: int64\n",
      "joinedDate: datetime64[ns]\n",
      "joinedCourses: object with 5027 unique values\n",
      "skills: object with 1270 unique values\n",
      "desired_skills: object with 2808 unique values\n",
      "isVerified: int64\n",
      "membershipDuration: int64\n",
      "course_count: int64\n",
      "skills_count: int64\n",
      "desired_skills_count: int64\n",
      "skill_overlap: int64\n",
      "user_activity_score: float64\n"
     ]
    }
   ],
   "execution_count": 114
  },
  {
   "cell_type": "markdown",
   "id": "e697925a143e0712",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Data Understanding and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "id": "8a7ca75d2db4fcb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T12:35:09.366485Z",
     "start_time": "2025-03-13T12:35:08.382445Z"
    }
   },
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Distribution of course counts\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.histplot(df['course_count'], kde=True)\n",
    "plt.title('Distribution of Course Counts')\n",
    "plt.xlabel('Number of Courses')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Distribution of skill counts\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.histplot(df['skills_count'], kde=True)\n",
    "plt.title('Distribution of Skill Counts')\n",
    "plt.xlabel('Number of Skills')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Distribution of desired skill counts\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.histplot(df['desired_skills_count'], kde=True)\n",
    "plt.title('Distribution of Desired Skill Counts')\n",
    "plt.xlabel('Number of Desired Skills')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Membership duration distribution\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.histplot(df['membershipDuration'], kde=True)\n",
    "plt.title('Distribution of Membership Duration')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('distributions.png')\n",
    "plt.close()"
   ],
   "outputs": [],
   "execution_count": 115
  },
  {
   "cell_type": "markdown",
   "id": "9065e128745242c7",
   "metadata": {},
   "source": [
    "# Function to extract all unique skills/courses from a column"
   ]
  },
  {
   "cell_type": "code",
   "id": "33b46cd18c959443",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T12:35:09.445706Z",
     "start_time": "2025-03-13T12:35:09.440404Z"
    }
   },
   "source": [
    "def extract_unique_items(df, column_name):\n",
    "    all_items = []\n",
    "    for items_str in df[column_name]:\n",
    "        if isinstance(items_str, str):\n",
    "            items = [item.strip() for item in items_str.split(',')]\n",
    "            all_items.extend(items)\n",
    "    return list(set(all_items))"
   ],
   "outputs": [],
   "execution_count": 116
  },
  {
   "cell_type": "markdown",
   "id": "62cb98c4bcb58b41",
   "metadata": {},
   "source": [
    "# Get unique items\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "883f21790111ea3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T12:35:09.689215Z",
     "start_time": "2025-03-13T12:35:09.631872Z"
    }
   },
   "source": [
    "all_courses = extract_unique_items(df, 'joinedCourses')\n",
    "all_skills = extract_unique_items(df, 'skills')\n",
    "all_desired_skills = extract_unique_items(df, 'desired_skills')\n",
    "print(f\"\\nTotal unique courses: {len(all_courses)}\")\n",
    "print(f\"Total unique skills: {len(all_skills)}\")\n",
    "print(f\"Total unique desired skills: {len(all_desired_skills)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total unique courses: 12\n",
      "Total unique skills: 13\n",
      "Total unique desired skills: 13\n"
     ]
    }
   ],
   "execution_count": 117
  },
  {
   "cell_type": "markdown",
   "id": "dc0ae70756391d2",
   "metadata": {},
   "source": [
    "# Top courses visualization"
   ]
  },
  {
   "cell_type": "code",
   "id": "7709cad99d6f128",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T12:35:10.390891Z",
     "start_time": "2025-03-13T12:35:09.785543Z"
    }
   },
   "source": [
    "def plot_top_items(df, column_name, title, n=10):\n",
    "    all_items = []\n",
    "    for items_str in df[column_name]:\n",
    "        if isinstance(items_str, str):\n",
    "            items = [item.strip() for item in items_str.split(',')]\n",
    "            all_items.extend(items)\n",
    "\n",
    "    item_counts = pd.Series(all_items).value_counts().head(n)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x=item_counts.values, y=item_counts.index)\n",
    "    plt.title(f'Top {n} {title}')\n",
    "    plt.xlabel('Count')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'top_{column_name}.png')\n",
    "    plt.close()\n",
    "\n",
    "# Plot top items for each category\n",
    "plot_top_items(df, 'joinedCourses', 'Courses')\n",
    "plot_top_items(df, 'skills', 'Skills')\n",
    "plot_top_items(df, 'desired_skills', 'Desired Skills')"
   ],
   "outputs": [],
   "execution_count": 118
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Feature Engineering for Skill Matching\n",
   "id": "35b80afbbac0143c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T12:35:10.520829Z",
     "start_time": "2025-03-13T12:35:10.395122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create binary features for skills and desired skills using CountVectorizer\n",
    "def create_binary_features(df, column_name):\n",
    "    vectorizer = CountVectorizer(tokenizer=lambda x: [item.strip() for item in x.split(',')])\n",
    "    binary_features = vectorizer.fit_transform(df[column_name].fillna(''))\n",
    "    binary_df = pd.DataFrame(binary_features.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "    return binary_df, vectorizer\n",
    "\n",
    "# Create binary feature matrices\n",
    "skills_binary, skills_vectorizer = create_binary_features(df, 'skills')\n",
    "desired_skills_binary, desired_skills_vectorizer = create_binary_features(df, 'desired_skills')\n",
    "courses_binary, courses_vectorizer = create_binary_features(df, 'joinedCourses')\n",
    "\n",
    "# Combine features for clustering\n",
    "combined_features = pd.concat([\n",
    "    skills_binary,\n",
    "    desired_skills_binary,\n",
    "    courses_binary,\n",
    "    df[['membershipDuration', 'course_count', 'skills_count', 'desired_skills_count', 'isVerified']].reset_index(drop=True)\n",
    "], axis=1)\n"
   ],
   "id": "96efd51e8ee92d1f",
   "outputs": [],
   "execution_count": 119
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Scale numerical features",
   "id": "954abbeb10251874"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T12:35:10.598978Z",
     "start_time": "2025-03-13T12:35:10.587462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scaler = StandardScaler()\n",
    "numerical_features = ['membershipDuration', 'course_count', 'skills_count', 'desired_skills_count']\n",
    "combined_features[numerical_features] = scaler.fit_transform(combined_features[numerical_features])\n",
    "\n",
    "# Convert boolean to int\n",
    "combined_features['isVerified'] = combined_features['isVerified'].astype(int)\n",
    "\n",
    "print(\"\\nFeature Engineering Complete\")\n",
    "print(f\"Total features: {combined_features.shape[1]}\")"
   ],
   "id": "a5d838ae3e90fe7e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Engineering Complete\n",
      "Total features: 43\n"
     ]
    }
   ],
   "execution_count": 120
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. Clustering with KMeans (KNN)\n",
   "id": "f9909ddec1409373"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T12:35:12.109775Z",
     "start_time": "2025-03-13T12:35:10.663889Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Determine optimal number of clusters using Elbow Method\n",
    "inertia = []\n",
    "k_range = range(2, 8)  # For a small dataset, we'll test up to 7 clusters\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(combined_features)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Plot Elbow Method\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_range, inertia, marker='o')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.grid(True)\n",
    "plt.savefig('elbow_method.png')\n",
    "plt.close()"
   ],
   "id": "8acfb43beefbdac6",
   "outputs": [],
   "execution_count": 121
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T12:35:13.261909Z",
     "start_time": "2025-03-13T12:35:12.181626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "optimal_k = 4\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "cluster_labels = kmeans.fit_predict(combined_features)\n",
    "\n",
    "# Add cluster labels to the original dataframe\n",
    "df['cluster'] = cluster_labels\n",
    "\n",
    "# Analyze clusters\n",
    "cluster_stats = df.groupby('cluster').agg({\n",
    "    'membershipDuration': 'mean',\n",
    "    'course_count': 'mean',\n",
    "    'skills_count': 'mean',\n",
    "    'desired_skills_count': 'mean',\n",
    "    'isVerified': 'mean',\n",
    "    'user_id': 'count'\n",
    "}).rename(columns={'user_id': 'count'})\n",
    "\n",
    "print(\"\\nCluster Statistics:\")\n",
    "print(cluster_stats)\n",
    "\n",
    "# Visualize clusters\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(\n",
    "    x='skills_count',\n",
    "    y='desired_skills_count',\n",
    "    hue='cluster',\n",
    "    size='course_count',\n",
    "    sizes=(50, 200),\n",
    "    palette='viridis',\n",
    "    data=df\n",
    ")\n",
    "plt.title('User Clusters by Skills and Desired Skills')\n",
    "plt.xlabel('Number of Current Skills')\n",
    "plt.ylabel('Number of Desired Skills')\n",
    "plt.savefig('user_clusters.png')\n",
    "plt.close()"
   ],
   "id": "e5fb9ad06ae70d72",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster Statistics:\n",
      "         membershipDuration  course_count  skills_count  desired_skills_count  \\\n",
      "cluster                                                                         \n",
      "0                798.812039      4.029075      4.471335              6.009419   \n",
      "1                795.778088      4.151394      2.613546              3.712351   \n",
      "2                799.176856      2.061499      2.435953              5.967977   \n",
      "3                801.097391      1.820870      4.328696              3.661304   \n",
      "\n",
      "         isVerified  count  \n",
      "cluster                     \n",
      "0          0.518428   2442  \n",
      "1          0.497610   2510  \n",
      "2          0.512009   2748  \n",
      "3          0.494783   2300  \n"
     ]
    }
   ],
   "execution_count": 122
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6. Skill Matching System using SVM",
   "id": "a26f9451934ae9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T12:35:14.174598Z",
     "start_time": "2025-03-13T12:35:13.324161Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare data for SVM - we'll predict if a user would be interested in \"Machine Learning\" as an example\n",
    "target_skill = \"Machine Learning\"\n",
    "\n",
    "# Check if the target skill is in the user's desired skills\n",
    "df['wants_' + target_skill.replace(' ', '_')] = df['desired_skills'].apply(\n",
    "    lambda x: 1 if target_skill in x else 0\n",
    ")\n",
    "\n",
    "# Feature matrix for prediction\n",
    "X_svm = combined_features\n",
    "y_svm = df['wants_' + target_skill.replace(' ', '_')]\n",
    "\n",
    "# Split data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_svm, y_svm, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train SVM model\n",
    "svm_model = SVC(kernel='linear', probability=True, random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = svm_model.predict(X_test)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Not Interested', 'Interested'],\n",
    "            yticklabels=['Not Interested', 'Interested'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title(f'Confusion Matrix for {target_skill} Interest Prediction')\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ],
   "id": "8974883ad6602976",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1556\n",
      "           1       1.00      1.00      1.00      1444\n",
      "\n",
      "    accuracy                           1.00      3000\n",
      "   macro avg       1.00      1.00      1.00      3000\n",
      "weighted avg       1.00      1.00      1.00      3000\n",
      "\n"
     ]
    }
   ],
   "execution_count": 123
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Skill Matching using Decision Tree\n",
    "\n"
   ],
   "id": "2390575603c9ccba"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-03-13T12:35:14.240477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Skill Matching using Decision Tree\n",
    "def skill_matching_comparison(df):\n",
    "    # Create feature vectors for all users based on their skills\n",
    "    # First, identify all unique skills in the dataset\n",
    "    all_skills = set()\n",
    "    for skills_str in df['skills'].dropna():\n",
    "        if isinstance(skills_str, str):\n",
    "            all_skills.update([skill.strip() for skill in skills_str.split(',')])\n",
    "\n",
    "    # Create binary feature matrix for skills\n",
    "    skill_features = pd.DataFrame(0, index=df.index, columns=list(all_skills))\n",
    "\n",
    "    # Fill the feature matrix\n",
    "    for idx, row in df.iterrows():\n",
    "        if isinstance(row['skills'], str):\n",
    "            user_skills = [skill.strip() for skill in row['skills'].split(',')]\n",
    "            for skill in user_skills:\n",
    "                if skill in skill_features.columns:\n",
    "                    skill_features.loc[idx, skill] = 1\n",
    "\n",
    "    # Add other relevant features\n",
    "    X = pd.concat([\n",
    "        skill_features,\n",
    "        df[['membershipDuration', 'course_count', 'skills_count', 'isVerified']].reset_index(drop=True)\n",
    "    ], axis=1)\n",
    "\n",
    "    # Scale numerical features\n",
    "    scaler = StandardScaler()\n",
    "    numerical_cols = ['membershipDuration', 'course_count', 'skills_count']\n",
    "    X[numerical_cols] = scaler.fit_transform(X[numerical_cols])\n",
    "\n",
    "    # Let's create multiple target variables for different skills to make the comparison more robust\n",
    "    target_skills = [\"Machine Learning\", \"Python\", \"JavaScript\", \"Data Science\", \"AI\"]\n",
    "\n",
    "    # Store results for each target skill\n",
    "    skill_results = {}\n",
    "\n",
    "    for target_skill in target_skills:\n",
    "        print(f\"\\nEvaluating matching for skill: {target_skill}\")\n",
    "\n",
    "        # Create target variable - does the user have this skill\n",
    "        y = df['skills'].apply(lambda x: 1 if isinstance(x, str) and target_skill in x else 0)\n",
    "\n",
    "        # Split the data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "        # Define the models\n",
    "        models = {\n",
    "            'SVM': SVC(probability=True, random_state=42),\n",
    "            'Decision Tree': DecisionTreeClassifier(max_depth=5, random_state=42),\n",
    "            'KNN': KNeighborsClassifier(n_neighbors=5)\n",
    "        }\n",
    "\n",
    "        # Dictionary to store results for this skill\n",
    "        model_results = {}\n",
    "\n",
    "        # Train and evaluate each model\n",
    "        for model_name, model in models.items():\n",
    "            # Train the model\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Make predictions\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            # Calculate metrics\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "            recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "            f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "            # Cross-validation scores\n",
    "            cv_f1 = cross_val_score(model, X, y, cv=5, scoring='f1')\n",
    "            cv_precision = cross_val_score(model, X, y, cv=5, scoring='precision')\n",
    "            cv_recall = cross_val_score(model, X, y, cv=5, scoring='recall')\n",
    "            cv_accuracy = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "            # Store results\n",
    "            model_results[model_name] = {\n",
    "                'accuracy': accuracy,\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'f1': f1,\n",
    "                'cv_accuracy_mean': np.mean(cv_accuracy),\n",
    "                'cv_precision_mean': np.mean(cv_precision),\n",
    "                'cv_recall_mean': np.mean(cv_recall),\n",
    "                'cv_f1_mean': np.mean(cv_f1)\n",
    "            }\n",
    "\n",
    "            print(f\"{model_name}: F1={f1:.3f}, Precision={precision:.3f}, Recall={recall:.3f}, Accuracy={accuracy:.3f}\")\n",
    "\n",
    "        skill_results[target_skill] = model_results\n",
    "\n",
    "    # Create plots comparing the models for each metric\n",
    "    metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
    "    metric_labels = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
    "\n",
    "    # Calculate average metrics across all skills\n",
    "    avg_results = {}\n",
    "    for model_name in models.keys():\n",
    "        avg_results[model_name] = {\n",
    "            metric: np.mean([skill_results[skill][model_name][metric] for skill in target_skills])\n",
    "            for metric in metrics\n",
    "        }\n",
    "\n",
    "    # First plot: comparing models across all metrics\n",
    "    plt.figure(figsize=(14, 8))\n",
    "\n",
    "    x = np.arange(len(metrics))\n",
    "    width = 0.25\n",
    "    model_names = list(models.keys())\n",
    "\n",
    "    for i, model_name in enumerate(model_names):\n",
    "        values = [avg_results[model_name][metric] for metric in metrics]\n",
    "        plt.bar(x + i*width, values, width, label=model_name)\n",
    "\n",
    "    plt.xlabel('Metrics')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Model Performance Comparison Across All Skills')\n",
    "    plt.xticks(x + width, metric_labels)\n",
    "    plt.legend()\n",
    "    plt.ylim(0, 1)\n",
    "    plt.savefig('model_metrics_comparison.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Second plot: comparing models for each skill on F1 score\n",
    "    plt.figure(figsize=(15, 8))\n",
    "\n",
    "    x = np.arange(len(target_skills))\n",
    "    width = 0.25\n",
    "\n",
    "    for i, model_name in enumerate(model_names):\n",
    "        values = [skill_results[skill][model_name]['f1'] for skill in target_skills]\n",
    "        plt.bar(x + i*width, values, width, label=model_name)\n",
    "\n",
    "    plt.xlabel('Target Skills')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.title('F1 Score Comparison by Skill')\n",
    "    plt.xticks(x + width, target_skills, rotation=45)\n",
    "    plt.legend()\n",
    "    plt.ylim(0, 1)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('f1_by_skill_comparison.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Create a detailed model comparison dataframe\n",
    "    comparison_data = []\n",
    "    for model_name in model_names:\n",
    "        for metric in metrics:\n",
    "            comparison_data.append({\n",
    "                'Model': model_name,\n",
    "                'Metric': metric.capitalize(),\n",
    "                'Score': avg_results[model_name][metric]\n",
    "            })\n",
    "\n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "    # Print summary of best models\n",
    "    print(\"\\n=== Model Performance Summary ===\")\n",
    "    best_model_by_metric = {}\n",
    "    for metric in metrics:\n",
    "        best_model = max(model_names, key=lambda m: avg_results[m][metric])\n",
    "        best_score = avg_results[best_model][metric]\n",
    "        best_model_by_metric[metric] = (best_model, best_score)\n",
    "        print(f\"Best model for {metric.capitalize()}: {best_model} with score {best_score:.3f}\")\n",
    "\n",
    "    # Create detailed output\n",
    "    results_overview = {\n",
    "        'skill_results': skill_results,\n",
    "        'avg_results': avg_results,\n",
    "        'comparison_df': comparison_df,\n",
    "        'best_model_by_metric': best_model_by_metric\n",
    "    }\n",
    "\n",
    "    # Return the final comparison and evaluation\n",
    "    return results_overview\n",
    "\n",
    "# Run comparison\n",
    "comparison_results = skill_matching_comparison(df)\n",
    "\n",
    "# Visualize the results as a table\n",
    "print(\"\\nDetailed Model Comparison:\")\n",
    "pivot_table = comparison_results['comparison_df'].pivot(index='Model', columns='Metric', values='Score')\n",
    "print(pivot_table.round(3))\n",
    "\n",
    "# Display a visual summary for easier interpretation\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(pivot_table, annot=True, cmap='viridis', fmt=\".3f\", linewidths=.5)\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_performance_heatmap.png')\n",
    "plt.close()\n",
    "\n",
    "# Find overall best model based on average of all metrics\n",
    "overall_scores = {}\n",
    "for model in comparison_results['avg_results'].keys():\n",
    "    metrics = comparison_results['avg_results'][model]\n",
    "    overall_scores[model] = sum(metrics.values()) / len(metrics)\n",
    "\n",
    "best_overall_model = max(overall_scores, key=overall_scores.get)\n",
    "print(f\"\\nOverall Best Model: {best_overall_model} with average score {overall_scores[best_overall_model]:.3f}\")"
   ],
   "id": "7e664a169a8edb54",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating matching for skill: Machine Learning\n",
      "SVM: F1=1.000, Precision=1.000, Recall=1.000, Accuracy=1.000\n",
      "Decision Tree: F1=1.000, Precision=1.000, Recall=1.000, Accuracy=1.000\n",
      "KNN: F1=0.786, Precision=1.000, Recall=0.648, Accuracy=0.965\n",
      "\n",
      "Evaluating matching for skill: Python\n",
      "SVM: F1=1.000, Precision=1.000, Recall=1.000, Accuracy=1.000\n",
      "Decision Tree: F1=1.000, Precision=1.000, Recall=1.000, Accuracy=1.000\n",
      "KNN: F1=0.991, Precision=0.999, Recall=0.984, Accuracy=0.995\n",
      "\n",
      "Evaluating matching for skill: JavaScript\n",
      "SVM: F1=1.000, Precision=1.000, Recall=1.000, Accuracy=1.000\n",
      "Decision Tree: F1=1.000, Precision=1.000, Recall=1.000, Accuracy=1.000\n",
      "KNN: F1=0.994, Precision=0.990, Recall=0.998, Accuracy=0.995\n",
      "\n",
      "Evaluating matching for skill: Data Science\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 7. User Matching for Peer Learning\n",
   "id": "5eda726af5588dfc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T11:53:43.140907Z",
     "start_time": "2025-03-13T11:53:43.114007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def find_learning_partners_enhanced(user_id, df, n_recommendations=3, algorithm='all'):\n",
    "    # Get user data\n",
    "    if user_id not in df['user_id'].values:\n",
    "        return {\"error\": \"User not found\"}\n",
    "\n",
    "    user = df[df['user_id'] == user_id].iloc[0]\n",
    "\n",
    "    # Extract user's skill info\n",
    "    user_desired_skills = [skill.strip() for skill in user['desired_skills'].split(',') if isinstance(user['desired_skills'], str)]\n",
    "    user_current_skills = [skill.strip() for skill in user['skills'].split(',') if isinstance(user['skills'], str)]\n",
    "\n",
    "    # Create feature matrix for all users\n",
    "    # 1. First encode all unique skills in the dataset\n",
    "    all_skills = set()\n",
    "    for skills_str in df['skills'].dropna():\n",
    "        if isinstance(skills_str, str):\n",
    "            all_skills.update([skill.strip() for skill in skills_str.split(',')])\n",
    "\n",
    "    skill_features = pd.DataFrame(0, index=df.index, columns=list(all_skills))\n",
    "\n",
    "    # Fill the feature matrix\n",
    "    for idx, row in df.iterrows():\n",
    "        if isinstance(row['skills'], str):\n",
    "            user_skills = [skill.strip() for skill in row['skills'].split(',')]\n",
    "            for skill in user_skills:\n",
    "                if skill in skill_features.columns:\n",
    "                    skill_features.loc[idx, skill] = 1\n",
    "\n",
    "    # Create a target variable - potential match for our user\n",
    "    # A user is a potential match if they have at least one skill our user wants\n",
    "    y_match = np.zeros(len(df))\n",
    "    for idx, row in df.iterrows():\n",
    "        if row['user_id'] != user_id and isinstance(row['skills'], str):\n",
    "            other_skills = [skill.strip() for skill in row['skills'].split(',')]\n",
    "            match_score = sum(1 for skill in user_desired_skills if skill in other_skills)\n",
    "            y_match[idx] = 1 if match_score > 0 else 0\n",
    "\n",
    "    # Combine with other user features\n",
    "    X = pd.concat([\n",
    "        skill_features,\n",
    "        df[['membershipDuration', 'course_count', 'skills_count', 'isVerified']].reset_index(drop=True)\n",
    "    ], axis=1)\n",
    "\n",
    "    # Scale numerical features\n",
    "    scaler = StandardScaler()\n",
    "    numerical_cols = ['membershipDuration', 'course_count', 'skills_count']\n",
    "    X[numerical_cols] = scaler.fit_transform(X[numerical_cols])\n",
    "\n",
    "    # Define and train the models\n",
    "    models = {\n",
    "        'SVM': SVC(probability=True, random_state=42),\n",
    "        'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "        'Decision Tree': DecisionTreeClassifier(random_state=42)\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "    for model_name, model in models.items():\n",
    "        # Train the model\n",
    "        model.fit(X, y_match)\n",
    "\n",
    "        # Get cross-validation scores\n",
    "        cv_scores = cross_val_score(model, X, y_match, cv=5, scoring='f1')\n",
    "        precision_scores = cross_val_score(model, X, y_match, cv=5, scoring='precision')\n",
    "\n",
    "        results[model_name] = {\n",
    "            'f1_score': np.mean(cv_scores),\n",
    "            'precision': np.mean(precision_scores),\n",
    "            'model': model\n",
    "        }\n",
    "\n",
    "    # Plot comparison results\n",
    "    if algorithm == 'all':\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        metrics = ['f1_score', 'precision']\n",
    "        model_names = list(results.keys())\n",
    "\n",
    "        X_axis = np.arange(len(model_names))\n",
    "        width = 0.35\n",
    "\n",
    "        plt.bar(X_axis - width/2, [results[model]['f1_score'] for model in model_names], width, label='F1 Score')\n",
    "        plt.bar(X_axis + width/2, [results[model]['precision'] for model in model_names], width, label='Precision')\n",
    "\n",
    "        plt.xticks(X_axis, model_names)\n",
    "        plt.xlabel('Models')\n",
    "        plt.ylabel('Scores')\n",
    "        plt.title('Model Performance Comparison')\n",
    "        plt.legend()\n",
    "        plt.ylim(0, 1)\n",
    "        plt.savefig('model_comparison.png')\n",
    "        plt.close()\n",
    "\n",
    "    # Select the best model or use the specified one\n",
    "    if algorithm == 'all':\n",
    "        # Find model with best F1 score\n",
    "        best_model = max(results, key=lambda x: results[x]['f1_score'])\n",
    "        selected_model = results[best_model]['model']\n",
    "        print(f\"Selected best model: {best_model} with F1 Score: {results[best_model]['f1_score']:.3f}\")\n",
    "    else:\n",
    "        selected_model = models[algorithm]\n",
    "\n",
    "    # Use the selected model to find matches\n",
    "    # Calculate match probabilities for all users\n",
    "    match_probs = selected_model.predict_proba(X)[:, 1]\n",
    "\n",
    "    # Create a list of potential matches\n",
    "    potential_matches = []\n",
    "    for idx, row in df.iterrows():\n",
    "        if row['user_id'] == user_id:\n",
    "            continue  # Skip the user themselves\n",
    "\n",
    "        # Only consider users with prediction probability > 0.5\n",
    "        if match_probs[idx] > 0.5:\n",
    "            other_skills = [skill.strip() for skill in row['skills'].split(',') if isinstance(row['skills'], str)]\n",
    "            other_desired_skills = [skill.strip() for skill in row['desired_skills'].split(',') if isinstance(row['desired_skills'], str)]\n",
    "\n",
    "            # Calculate exact matching skills for output\n",
    "            matching_skills = [skill for skill in user_desired_skills if skill in other_skills]\n",
    "            can_learn_from_you = [skill for skill in other_desired_skills if skill in user_current_skills]\n",
    "\n",
    "            if matching_skills:  # Only include if there's at least one matching skill\n",
    "                potential_matches.append({\n",
    "                    'user_id': row['user_id'],\n",
    "                    'skills': row['skills'],\n",
    "                    'matching_skills': matching_skills,\n",
    "                    'can_learn_from_you': can_learn_from_you,\n",
    "                    'match_score': match_probs[idx]\n",
    "                })\n",
    "\n",
    "    # Sort by match probability (higher is better)\n",
    "    sorted_matches = sorted(potential_matches, key=lambda x: x['match_score'], reverse=True)\n",
    "\n",
    "    # Return results\n",
    "    return {\n",
    "        'model_comparison': results,\n",
    "        'recommendations': sorted_matches[:n_recommendations]\n",
    "    }"
   ],
   "id": "e3e818a5e286a8f5",
   "outputs": [],
   "execution_count": 101
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T11:54:22.348280Z",
     "start_time": "2025-03-13T11:53:43.237108Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get recommendations using all models and comparing them\n",
    "results = find_learning_partners_enhanced(user_id=79, df=df, n_recommendations=4)\n",
    "\n",
    "# Print model comparison\n",
    "print(\"Model Performance Comparison:\")\n",
    "for model, metrics in results['model_comparison'].items():\n",
    "    print(f\"{model}: F1 Score = {metrics['f1_score']:.3f}, Precision = {metrics['precision']:.3f}\")\n",
    "\n",
    "# Print recommendations\n",
    "print(\"\\nRecommended Learning Partners:\")\n",
    "for i, match in enumerate(results['recommendations'], 1):\n",
    "    print(f\"\\nMatch {i}:\")\n",
    "    print(f\"User ID: {match['user_id']}\")\n",
    "    print(f\"Match score: {match['match_score']:.3f}\")\n",
    "    print(f\"Can teach you: {', '.join(match['matching_skills'])}\")\n",
    "    print(f\"Can learn from you: {', '.join(match['can_learn_from_you'])}\")\n",
    "\n",
    "# Or use a specific algorithm\n",
    "svm_results = find_learning_partners_enhanced(user_id=1, df=df, algorithm='SVM')\n",
    "print(\"svm_results\",svm_results)"
   ],
   "id": "8205019c0d48aaa3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected best model: SVM with F1 Score: 1.000\n",
      "Model Performance Comparison:\n",
      "SVM: F1 Score = 1.000, Precision = 1.000\n",
      "KNN: F1 Score = 0.992, Precision = 0.995\n",
      "Decision Tree: F1 Score = 1.000, Precision = 1.000\n",
      "\n",
      "Recommended Learning Partners:\n",
      "\n",
      "Match 1:\n",
      "User ID: 3\n",
      "Match score: 1.000\n",
      "Can teach you: CSS, Java\n",
      "Can learn from you: Nodejs\n",
      "\n",
      "Match 2:\n",
      "User ID: 8\n",
      "Match score: 1.000\n",
      "Can teach you: CSS, Data Science\n",
      "Can learn from you: Nodejs\n",
      "\n",
      "Match 3:\n",
      "User ID: 11\n",
      "Match score: 1.000\n",
      "Can teach you: CSS, Excel\n",
      "Can learn from you: \n",
      "\n",
      "Match 4:\n",
      "User ID: 12\n",
      "Match score: 1.000\n",
      "Can teach you: CSS, Excel\n",
      "Can learn from you: HTML\n",
      "svm_results {'model_comparison': {'SVM': {'f1_score': np.float64(1.0), 'precision': np.float64(1.0), 'model': SVC(probability=True, random_state=42)}, 'KNN': {'f1_score': np.float64(0.9793536566197508), 'precision': np.float64(0.9976379450018629), 'model': KNeighborsClassifier()}, 'Decision Tree': {'f1_score': np.float64(1.0), 'precision': np.float64(1.0), 'model': DecisionTreeClassifier(random_state=42)}}, 'recommendations': [{'user_id': 3, 'skills': 'HTML, CSS, Java', 'matching_skills': ['CSS', 'Java'], 'can_learn_from_you': ['SQL'], 'match_score': np.float64(0.9999999999999699)}, {'user_id': 4, 'skills': 'HTML, Excel, SQL, Java, Blockchain', 'matching_skills': ['Java', 'Blockchain'], 'can_learn_from_you': ['SQL'], 'match_score': np.float64(0.9999999999999699)}, {'user_id': 8, 'skills': 'HTML, CSS, SQL, Data Science', 'matching_skills': ['CSS', 'Data Science'], 'can_learn_from_you': [], 'match_score': np.float64(0.9999999999999699)}]}\n"
     ]
    }
   ],
   "execution_count": 102
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 8. NLP Chatbot for Skill Guidance",
   "id": "a18d8a11f53f3d1a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T11:54:22.360372Z",
     "start_time": "2025-03-13T11:54:22.353576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# First, let's create a dataset of common questions and their responses for our skill guidance chatbot\n",
    "skill_conversation_data = [\n",
    "    {\n",
    "        'question': 'What courses should I take to learn Machine Learning?',\n",
    "        'answer': 'To learn Machine Learning, start with Python, Statistics, and Linear Algebra basics, then take courses on ML algorithms, neural networks, and practical ML projects.'\n",
    "    },\n",
    "    {\n",
    "        'question': 'How do I learn Data Science?',\n",
    "        'answer': 'To learn Data Science, I recommend courses in Python or R, statistics, data visualization, machine learning, and big data technologies. Start with the fundamentals and then work on real-world projects.'\n",
    "    },\n",
    "    {\n",
    "        'question': 'What skills do I need for web development?',\n",
    "        'answer': 'For web development, core skills include HTML, CSS, and JavaScript. For frontend, learn frameworks like React, Vue, or Angular. For backend, consider Node.js, Django, or Ruby on Rails, along with database skills.'\n",
    "    },\n",
    "    {\n",
    "        'question': 'How long does it take to learn Python?',\n",
    "        'answer': 'Learning Python basics takes 2-4 weeks, becoming proficient takes 3-6 months, and mastery requires ongoing practice. The timeline depends on your prior programming experience and study consistency.'\n",
    "    },\n",
    "    {\n",
    "        'question': 'Which is better to learn first, Java or Python?',\n",
    "        'answer': 'Python is often recommended for beginners due to its simpler syntax and readability. Java has a steeper learning curve but is valuable for enterprise applications. Choose based on your career goals.'\n",
    "    },\n",
    "    {\n",
    "        'question': 'What should I learn after HTML and CSS?',\n",
    "        'answer': 'After HTML and CSS, learn JavaScript to add interactivity to websites. Then consider a frontend framework like React, Vue, or Angular, and basic backend concepts for full-stack development.'\n",
    "    },\n",
    "    {\n",
    "        'question': 'How to start learning AI?',\n",
    "        'answer': 'Start learning AI with Python programming, statistics, and linear algebra. Then progress to machine learning fundamentals, neural networks, and specialized areas like NLP or computer vision.'\n",
    "    },\n",
    "    {\n",
    "        'question': 'What are the best resources to learn SQL?',\n",
    "        'answer': 'Great SQL learning resources include interactive platforms like SQLZoo and Mode Analytics, courses on Coursera and DataCamp, and practice through real database projects.'\n",
    "    },\n",
    "    {\n",
    "        'question': 'How do I find a study partner?',\n",
    "        'answer': 'You can find a study partner by using our matching system, joining relevant online communities, participating in forums related to your interests, or attending virtual meetups and hackathons.'\n",
    "    },\n",
    "    {\n",
    "        'question': 'What skills are in demand right now?',\n",
    "        'answer': 'Currently in-demand skills include Machine Learning, Data Science, Cloud Computing (AWS/Azure), DevOps, Full-Stack Development, Cybersecurity, and Blockchain development.'\n",
    "    }\n",
    "]\n"
   ],
   "id": "6693abfde284c66f",
   "outputs": [],
   "execution_count": 103
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Preprocess text function (tokenization, removing stopwords, lemmatization)",
   "id": "aa05589b01109542"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T11:54:22.480928Z",
     "start_time": "2025-03-13T11:54:22.433470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nltk.download('punkt_tab')\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove special characters\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    # Lemmatize\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Preprocess the conversation data\n",
    "processed_questions = [preprocess_text(item['question']) for item in skill_conversation_data]\n",
    "\n",
    "# Create TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(processed_questions)\n"
   ],
   "id": "80eb7bf7666b375e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\farou\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T11:54:22.566088Z",
     "start_time": "2025-03-13T11:54:22.561034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to get the most similar response\n",
    "def get_chatbot_response(user_input, threshold=0.3):\n",
    "    # Preprocess the user input\n",
    "    processed_input = preprocess_text(user_input)\n",
    "\n",
    "    # Vectorize the user input\n",
    "    user_vector = tfidf_vectorizer.transform([processed_input])\n",
    "\n",
    "    # Calculate similarity scores\n",
    "    similarity_scores = cosine_similarity(user_vector, tfidf_matrix)[0]\n",
    "\n",
    "    # Get the index of the most similar question\n",
    "    max_similarity_index = np.argmax(similarity_scores)\n",
    "    max_similarity = similarity_scores[max_similarity_index]\n",
    "\n",
    "    # If similarity is above threshold, return the corresponding answer\n",
    "    if max_similarity >= threshold:\n",
    "        return skill_conversation_data[max_similarity_index]['answer']\n",
    "    else:\n",
    "        # Generate a generic response for questions not in our dataset\n",
    "        return \"I'm not sure about that specific topic. However, I can help you find courses or study partners for various skills. Could you tell me what skills you're interested in learning?\"\n",
    "\n"
   ],
   "id": "ce2f9aeee379a5b6",
   "outputs": [],
   "execution_count": 105
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Testing the NLP",
   "id": "7f229c538177bf9f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T11:54:22.727169Z",
     "start_time": "2025-03-13T11:54:22.710681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test the chatbot with sample questions\n",
    "sample_questions = [\n",
    "    \"What should I learn to become a data scientist?\",\n",
    "    \"I want to learn web development, what should I study?\",\n",
    "    \"How can I find someone to study programming with?\",\n",
    "    \"What programming language should I learn first?\",\n",
    "    \"I'm interested in artificial intelligence\"\n",
    "]\n",
    "\n",
    "print(\"\\nChatbot Response Examples:\")\n",
    "for question in sample_questions:\n",
    "    print(f\"\\nQ: {question}\")\n",
    "    print(f\"A: {get_chatbot_response(question)}\")\n",
    "\n",
    "## 9. Building a complete skill guidance system\n",
    "\n",
    "def skill_guidance_system(user_id, user_query, df):\n",
    "    \"\"\"\n",
    "    Combined skill guidance system that leverages all components:\n",
    "    1. Chatbot for general skill guidance\n",
    "    2. User matching for peer learning\n",
    "    3. Course recommendations based on desired skills\n",
    "    \"\"\"\n",
    "    response = {}\n",
    "\n",
    "    # Get chatbot response\n",
    "    chatbot_answer = get_chatbot_response(user_query)\n",
    "    response['guidance'] = chatbot_answer\n",
    "\n",
    "    # If user_id is provided, get personalized recommendations\n",
    "    if user_id and user_id in df['user_id'].values:\n",
    "        # Get matching learning partners\n",
    "        learning_partners = find_learning_partners_enhanced(user_id, df, n_recommendations=2)\n",
    "        response['learning_partners'] = learning_partners\n",
    "\n",
    "        # Get user's desired skills\n",
    "        user_desired_skills = df[df['user_id'] == user_id]['desired_skills'].iloc[0].split(', ')\n",
    "\n",
    "        # Recommend courses based on desired skills (simple frequency-based recommendation)\n",
    "        recommended_courses = []\n",
    "        for skill in user_desired_skills:\n",
    "            skill = skill.strip()\n",
    "            # Find users who have this skill\n",
    "            users_with_skill = df[df['skills'].apply(lambda x: skill in x)]\n",
    "            # Get courses they took\n",
    "            if not users_with_skill.empty:\n",
    "                courses = []\n",
    "                for course_list in users_with_skill['joinedCourses']:\n",
    "                    courses.extend([c.strip() for c in course_list.split(',')])\n",
    "\n",
    "                # Get most common courses\n",
    "                if courses:\n",
    "                    course_counts = pd.Series(courses).value_counts()\n",
    "                    top_courses = course_counts.head(2).index.tolist()\n",
    "                    recommended_courses.append({\n",
    "                        'skill': skill,\n",
    "                        'recommended_courses': top_courses\n",
    "                    })\n",
    "\n",
    "        response['course_recommendations'] = recommended_courses\n",
    "\n",
    "    return response\n"
   ],
   "id": "13e903abc211530d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chatbot Response Examples:\n",
      "\n",
      "Q: What should I learn to become a data scientist?\n",
      "A: To learn Data Science, I recommend courses in Python or R, statistics, data visualization, machine learning, and big data technologies. Start with the fundamentals and then work on real-world projects.\n",
      "\n",
      "Q: I want to learn web development, what should I study?\n",
      "A: For web development, core skills include HTML, CSS, and JavaScript. For frontend, learn frameworks like React, Vue, or Angular. For backend, consider Node.js, Django, or Ruby on Rails, along with database skills.\n",
      "\n",
      "Q: How can I find someone to study programming with?\n",
      "A: You can find a study partner by using our matching system, joining relevant online communities, participating in forums related to your interests, or attending virtual meetups and hackathons.\n",
      "\n",
      "Q: What programming language should I learn first?\n",
      "A: Python is often recommended for beginners due to its simpler syntax and readability. Java has a steeper learning curve but is valuable for enterprise applications. Choose based on your career goals.\n",
      "\n",
      "Q: I'm interested in artificial intelligence\n",
      "A: I'm not sure about that specific topic. However, I can help you find courses or study partners for various skills. Could you tell me what skills you're interested in learning?\n"
     ]
    }
   ],
   "execution_count": 106
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Whole System Testing",
   "id": "ce7603b5847094dd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T11:57:50.689393Z",
     "start_time": "2025-03-13T11:57:31.102189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_user_id = 1\n",
    "test_query = \"I want to learn mACHINE LEARNING AND I DONT KNOW WHERE TO START\"\n",
    "\n",
    "guidance_result = skill_guidance_system(test_user_id, test_query, df)\n",
    "\n",
    "print(\"\\nComplete Skill Guidance System Output:\")\n",
    "print(\"\\nChatbot Guidance:\")\n",
    "print(guidance_result['guidance'])\n",
    "\n",
    "print(\"\\nRecommended Learning Partners:\")\n",
    "for partner in guidance_result['learning_partners']:\n",
    "    print(partner)\n",
    "\n",
    "print(\"\\nCourse Recommendations:\")\n",
    "for rec in guidance_result['course_recommendations']:\n",
    "    print(f\"For {rec['skill']}: {', '.join(rec['recommended_courses'])}\")\n"
   ],
   "id": "94210feb5816d00a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected best model: SVM with F1 Score: 1.000\n",
      "\n",
      "Complete Skill Guidance System Output:\n",
      "\n",
      "Chatbot Guidance:\n",
      "Start learning AI with Python programming, statistics, and linear algebra. Then progress to machine learning fundamentals, neural networks, and specialized areas like NLP or computer vision.\n",
      "\n",
      "Recommended Learning Partners:\n",
      "model_comparison\n",
      "recommendations\n",
      "\n",
      "Course Recommendations:\n",
      "For CSS: Excel, HTML\n",
      "For Java: CSS, Data Science\n",
      "For Machine Learning: AI, Java\n",
      "For Blockchain: Data Science, HTML\n",
      "For Data Science: CSS, AI\n"
     ]
    }
   ],
   "execution_count": 108
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Chatbot with Enhanced Skill Matching without NLP",
   "id": "4c247ca8bbc55ca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T11:58:12.288248Z",
     "start_time": "2025-03-13T11:58:11.667732Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def enhanced_skill_chatbot(df):\n",
    "    # Create training data for intent classification\n",
    "    intents = [\n",
    "        {\n",
    "            'tag': 'course_recommendation',\n",
    "            'patterns': [\n",
    "                \"What courses should I take to learn Machine Learning?\",\n",
    "                \"How do I learn Data Science?\",\n",
    "                \"Recommend courses for web development\",\n",
    "                \"What should I study for AI?\",\n",
    "                \"Best courses for Python\",\n",
    "                \"Suggest courses for JavaScript\",\n",
    "                \"How to learn blockchain\",\n",
    "                \"Courses for SQL\",\n",
    "                \"What should I learn for data analysis\",\n",
    "                \"Recommend learning path for frontend\"\n",
    "            ],\n",
    "            'responses': [\n",
    "                \"Based on your interests, I recommend starting with {}, then moving to {}.\",\n",
    "                \"To learn {}, I suggest these courses: {}.\",\n",
    "                \"The best learning path for {} includes: {}.\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'tag': 'skill_duration',\n",
    "            'patterns': [\n",
    "                \"How long does it take to learn Python?\",\n",
    "                \"Time needed to become a web developer\",\n",
    "                \"How much time to learn JavaScript?\",\n",
    "                \"How long until I can work as a data scientist?\",\n",
    "                \"Months required to master machine learning\",\n",
    "                \"Time investment for learning SQL\",\n",
    "                \"How long to learn React\",\n",
    "                \"Time needed for Java proficiency\",\n",
    "                \"How long does it take to learn AI\",\n",
    "                \"Duration to become skilled in blockchain\"\n",
    "            ],\n",
    "            'responses': [\n",
    "                \"Learning {} typically takes {} months of consistent practice.\",\n",
    "                \"Most people become proficient in {} after {} months of study.\",\n",
    "                \"Expect to spend about {} months to master {}.\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'tag': 'find_partners',\n",
    "            'patterns': [\n",
    "                \"How can I find a study partner?\",\n",
    "                \"Looking for someone to practice coding with\",\n",
    "                \"Need a partner to learn JavaScript\",\n",
    "                \"Find me someone to study with\",\n",
    "                \"How to find peer learners\",\n",
    "                \"Connect me with study partners\",\n",
    "                \"Study group for Python\",\n",
    "                \"Partner for pair programming\",\n",
    "                \"Need help finding learning buddies\",\n",
    "                \"Match me with a study partner\"\n",
    "            ],\n",
    "            'responses': [\n",
    "                \"I can help you find learning partners with similar interests.\",\n",
    "                \"Let me match you with peers who are looking to study {}.\",\n",
    "                \"Our matching algorithm can find you ideal study partners based on your interests.\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'tag': 'skill_comparison',\n",
    "            'patterns': [\n",
    "                \"Which is better to learn first, Java or Python?\",\n",
    "                \"React vs Angular, which should I learn?\",\n",
    "                \"Compare data science and machine learning\",\n",
    "                \"Python or R for data analysis?\",\n",
    "                \"JavaScript or TypeScript for web development\",\n",
    "                \"AWS vs Azure for cloud computing\",\n",
    "                \"Flutter vs React Native\",\n",
    "                \"Compare SQL and NoSQL\",\n",
    "                \"Django vs Flask for Python web development\",\n",
    "                \"TensorFlow or PyTorch for machine learning\"\n",
    "            ],\n",
    "            'responses': [\n",
    "                \"When comparing {} and {}, consider your goals: {}.\",\n",
    "                \"Both {} and {} are valuable, but {} might be better for beginners.\",\n",
    "                \"For your needs, {} might be more suitable than {} because {}.\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'tag': 'trending_skills',\n",
    "            'patterns': [\n",
    "                \"What skills are in demand right now?\",\n",
    "                \"Popular programming languages in 2023\",\n",
    "                \"Trending tech skills\",\n",
    "                \"What should I learn to get a job?\",\n",
    "                \"Most valuable skills in tech\",\n",
    "                \"Current tech trends\",\n",
    "                \"What are employers looking for\",\n",
    "                \"Highest paid skills in tech\",\n",
    "                \"What's hot in programming right now\",\n",
    "                \"Future-proof skills to learn\"\n",
    "            ],\n",
    "            'responses': [\n",
    "                \"Currently trending skills include: {}.\",\n",
    "                \"Employers are actively seeking candidates with: {}.\",\n",
    "                \"For maximum employability, consider learning: {}.\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Prepare training data\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for intent in intents:\n",
    "        for pattern in intent['patterns']:\n",
    "            X.append(pattern)\n",
    "            y.append(intent['tag'])\n",
    "\n",
    "    # Split data for training and evaluation\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Create pipeline with TF-IDF and classifiers\n",
    "    classifiers = {\n",
    "        'SVM': Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "            ('clf', SVC(kernel='linear', probability=True, random_state=42))\n",
    "        ]),\n",
    "        'Decision Tree': Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "            ('clf', DecisionTreeClassifier(random_state=42))\n",
    "        ]),\n",
    "        'KNN': Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "            ('clf', KNeighborsClassifier(n_neighbors=5))\n",
    "        ])\n",
    "    }\n",
    "\n",
    "    # Dictionary to store results\n",
    "    results = {}\n",
    "\n",
    "    # Train and evaluate each classifier\n",
    "    for name, classifier in classifiers.items():\n",
    "        # Cross-validation scores\n",
    "        cv_accuracy = cross_val_score(classifier, X, y, cv=5, scoring='accuracy')\n",
    "        cv_f1 = cross_val_score(classifier, X, y, cv=5, scoring='f1_macro')\n",
    "        cv_precision = cross_val_score(classifier, X, y, cv=5, scoring='precision_macro')\n",
    "        cv_recall = cross_val_score(classifier, X, y, cv=5, scoring='recall_macro')\n",
    "\n",
    "        # Train on training set\n",
    "        classifier.fit(X_train, y_train)\n",
    "\n",
    "        # Test on test set\n",
    "        y_pred = classifier.predict(X_test)\n",
    "\n",
    "        # Store results\n",
    "        results[name] = {\n",
    "            'cv_accuracy_mean': np.mean(cv_accuracy),\n",
    "            'cv_accuracy_std': np.std(cv_accuracy),\n",
    "            'cv_f1_mean': np.mean(cv_f1),\n",
    "            'cv_f1_std': np.std(cv_f1),\n",
    "            'cv_precision_mean': np.mean(cv_precision),\n",
    "            'cv_precision_std': np.std(cv_precision),\n",
    "            'cv_recall': np.mean(cv_recall),\n",
    "            'test_f1': f1_score(y_test, y_pred, average='macro'),\n",
    "            'test_precision': precision_score(y_test, y_pred, average='macro'),\n",
    "            'classifier': classifier,\n",
    "            'classification_report': classification_report(y_test, y_pred)\n",
    "        }\n",
    "\n",
    "    # Plot comparison results\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    metrics = ['cv_accuracy_mean', 'cv_f1_mean', 'cv_precision_mean', 'test_f1', 'test_precision']\n",
    "    metric_labels = ['Accuracy', 'F1 Score', 'Precision', 'Test F1', 'Test Precision']\n",
    "    model_names = list(results.keys())\n",
    "\n",
    "    x = np.arange(len(model_names))\n",
    "    width = 0.25\n",
    "\n",
    "    for i, metric in enumerate(metrics):\n",
    "        values = [results[model][metric] for model in model_names]\n",
    "        plt.bar(x + i*width, values, width, label=metric_labels[i])\n",
    "\n",
    "    plt.xlabel('Models')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Classifier Performance Comparison')\n",
    "    plt.xticks(x + width, model_names)\n",
    "    plt.legend()\n",
    "    plt.ylim(0, 1)\n",
    "    plt.savefig('chatbot_classifier_comparison.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Find best performing model based on F1 score\n",
    "    best_model = max(results, key=lambda x: results[x]['cv_f1_mean'])\n",
    "\n",
    "    # Define response function using the best classifier\n",
    "    def get_response(user_input):\n",
    "        # Predict intent\n",
    "        intent_pred = results[best_model]['classifier'].predict([user_input])[0]\n",
    "        intent_probs = results[best_model]['classifier'].predict_proba([user_input])[0]\n",
    "        max_prob = max(intent_probs)\n",
    "\n",
    "        # Find matching intent\n",
    "        for intent in intents:\n",
    "            if intent['tag'] == intent_pred:\n",
    "                # Select a random response template\n",
    "                response_template = np.random.choice(intent['responses'])\n",
    "\n",
    "                # Fill in the template with context-specific information\n",
    "                if intent['tag'] == 'course_recommendation':\n",
    "                    # Extract skills from user input using keyword matching\n",
    "                    skills = []\n",
    "                    for skill in [\"Python\", \"JavaScript\", \"Data Science\", \"Machine Learning\",\n",
    "                                 \"SQL\", \"AI\", \"Web Development\", \"Java\", \"React\", \"Node.js\"]:\n",
    "                        if skill.lower() in user_input.lower():\n",
    "                            skills.append(skill)\n",
    "\n",
    "                    if not skills:\n",
    "                        skills = [\"programming\", \"tech skills\"]\n",
    "\n",
    "                    # Get top courses for those skills from our dataset\n",
    "                    related_courses = []\n",
    "                    for skill in skills[:2]:  # Use at most 2 skills\n",
    "                        # Find users with this skill\n",
    "                        users_with_skill = df[df['skills'].apply(lambda x: isinstance(x, str) and skill in x)]\n",
    "                        if not users_with_skill.empty:\n",
    "                            # Get courses they took\n",
    "                            courses = []\n",
    "                            for course_list in users_with_skill['joinedCourses']:\n",
    "                                if isinstance(course_list, str):\n",
    "                                    courses.extend([c.strip() for c in course_list.split(',')])\n",
    "\n",
    "                            if courses:\n",
    "                                # Get most frequent course\n",
    "                                course_counts = pd.Series(courses).value_counts()\n",
    "                                top_course = course_counts.index[0] if not course_counts.empty else \"introductory courses\"\n",
    "                                related_courses.append(top_course)\n",
    "\n",
    "                    if not related_courses:\n",
    "                        related_courses = [\"beginner tutorials\", \"online courses\"]\n",
    "\n",
    "                    return response_template.format(skills[0], \", \".join(related_courses))\n",
    "\n",
    "                elif intent['tag'] == 'skill_duration':\n",
    "                    # Extract skills from user input\n",
    "                    skills = []\n",
    "                    for skill in [\"Python\", \"JavaScript\", \"Data Science\", \"Machine Learning\",\n",
    "                                 \"SQL\", \"AI\", \"Web Development\", \"Java\", \"React\", \"Node.js\"]:\n",
    "                        if skill.lower() in user_input.lower():\n",
    "                            skills.append(skill)\n",
    "\n",
    "                    if not skills:\n",
    "                        skill = \"this technology\"\n",
    "                    else:\n",
    "                        skill = skills[0]\n",
    "\n",
    "                    # Estimate time based on complexity\n",
    "                    complexity = {\n",
    "                        \"Python\": \"2-3\", \"JavaScript\": \"3-4\", \"HTML\": \"1-2\", \"CSS\": \"2-3\",\n",
    "                        \"Java\": \"4-6\", \"SQL\": \"1-3\", \"Machine Learning\": \"6-12\",\n",
    "                        \"Data Science\": \"6-12\", \"AI\": \"9-18\", \"Web Development\": \"4-8\"\n",
    "                    }\n",
    "\n",
    "                    time = complexity.get(skill, \"3-6\")\n",
    "                    return response_template.format(skill, time)\n",
    "\n",
    "                # Add more intent-specific logic as needed\n",
    "\n",
    "                # For intents without specific handling, just return a response\n",
    "                return np.random.choice(intent['responses'])\n",
    "\n",
    "        # Fallback response if no intent matched (shouldn't happen)\n",
    "        return \"I'm not sure I understand. Could you rephrase your question?\"\n",
    "\n",
    "    # Create a comprehensive response\n",
    "    print(\"\\n----- Chatbot Model Evaluation -----\")\n",
    "    print(f\"Best performing model: {best_model}\")\n",
    "    print(\"\\nModel Comparison:\")\n",
    "    for name, metrics in results.items():\n",
    "        print(f\"\\n{name}:\")\n",
    "        print(f\"  Cross-validation Accuracy: {metrics['cv_accuracy_mean']:.3f} (±{metrics['cv_accuracy_std']:.3f})\")\n",
    "        print(f\"  Cross-validation F1 Score: {metrics['cv_f1_mean']:.3f} (±{metrics['cv_f1_std']:.3f})\")\n",
    "        print(f\"  Cross-validation Precision: {metrics['cv_precision_mean']:.3f} (±{metrics['cv_precision_std']:.3f})\")\n",
    "        print(f\"  Test F1 Score: {metrics['test_f1']:.3f}\")\n",
    "        print(f\"  Test Precision: {metrics['test_precision']:.3f}\")\n",
    "\n",
    "    # Return both the evaluation results and the response function\n",
    "    return {\n",
    "        'evaluation': results,\n",
    "        'get_response': get_response,\n",
    "        'best_model': best_model\n",
    "    }\n",
    "\n",
    "# Test the enhanced chatbot\n",
    "chatbot = enhanced_skill_chatbot(df)\n",
    "\n",
    "# Test some questions\n",
    "test_questions = [\n",
    "    \"What courses should I take to learn Machine Learning?\",\n",
    "    \"How long does it take to learn Python?\",\n",
    "    \"Can you help me find a study partner for JavaScript?\",\n",
    "    \"Should I learn React or Angular first?\",\n",
    "    \"What are the most in-demand skills right now?\"\n",
    "]\n",
    "\n",
    "print(\"\\n----- Chatbot Response Examples -----\")\n",
    "for question in test_questions:\n",
    "    print(f\"\\nQ: {question}\")\n",
    "    print(f\"A: {chatbot['get_response'](question)}\")"
   ],
   "id": "f16bde641054d779",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Chatbot Model Evaluation -----\n",
      "Best performing model: SVM\n",
      "\n",
      "Model Comparison:\n",
      "\n",
      "SVM:\n",
      "  Cross-validation Accuracy: 0.680 (±0.040)\n",
      "  Cross-validation F1 Score: 0.671 (±0.056)\n",
      "  Cross-validation Precision: 0.710 (±0.065)\n",
      "  Test F1 Score: 0.576\n",
      "  Test Precision: 0.567\n",
      "\n",
      "Decision Tree:\n",
      "  Cross-validation Accuracy: 0.620 (±0.098)\n",
      "  Cross-validation F1 Score: 0.598 (±0.116)\n",
      "  Cross-validation Precision: 0.669 (±0.142)\n",
      "  Test F1 Score: 0.377\n",
      "  Test Precision: 0.378\n",
      "\n",
      "KNN:\n",
      "  Cross-validation Accuracy: 0.640 (±0.049)\n",
      "  Cross-validation F1 Score: 0.635 (±0.053)\n",
      "  Cross-validation Precision: 0.727 (±0.079)\n",
      "  Test F1 Score: 0.700\n",
      "  Test Precision: 0.800\n",
      "\n",
      "----- Chatbot Response Examples -----\n",
      "\n",
      "Q: What courses should I take to learn Machine Learning?\n",
      "A: Based on your interests, I recommend starting with Machine Learning, then moving to AI.\n",
      "\n",
      "Q: How long does it take to learn Python?\n",
      "A: Most people become proficient in Python after 2-3 months of study.\n",
      "\n",
      "Q: Can you help me find a study partner for JavaScript?\n",
      "A: Our matching algorithm can find you ideal study partners based on your interests.\n",
      "\n",
      "Q: Should I learn React or Angular first?\n",
      "A: When comparing {} and {}, consider your goals: {}.\n",
      "\n",
      "Q: What are the most in-demand skills right now?\n",
      "A: Currently trending skills include: {}.\n"
     ]
    }
   ],
   "execution_count": 110
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
